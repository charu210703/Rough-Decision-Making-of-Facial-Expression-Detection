{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOeTDgmQGiuLZwlKbIhOLD6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/charu210703/Rough-Decision-Making-of-Facial-Expression-Detection/blob/main/Rough_Decision_Making_of_Facial_Expression_Detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As problems evolve in complexity, thereâ€™s a growing need for robust\n",
        "methods to manage uncertain, incomplete, and imprecise information.\n",
        "The motivation behind our proposed model lies in the quest for a\n",
        "nuanced approach to handling decision making problems, especially in\n",
        "the presence of uncertain information.\n"
      ],
      "metadata": {
        "id": "MdXZI4VCbZBq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Special thanks are extended to Dr. Shan Li and Dr. Weihong Dong\n",
        "for providing the RAF-DB database, enabling the implementation of\n",
        "our mathematical model. As the dataset is private and only available for non-commercial research purposes only, we wouldn't be able to upload it in a public repo. <br> Let the dataset.csv be a csv file we have generated from the dataset, containing the following parameters:<br>\n",
        "\n",
        "\n",
        "1.   Image name\n",
        "2.   Age\n",
        "3.   Gender\n",
        "4.   Emotion (7 classes of basic emotions)\n",
        "5.   x and y coordinates of 5 accurate landmark locations\n",
        "6.   x and y coordinates of 37 automatic landmark locations\n"
      ],
      "metadata": {
        "id": "iRRblfNDcO4i"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l6jktKqA6U7P"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import math\n",
        "df = pd.read_csv('<dataset csv file>')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We focused on five key facial parameters using geometric features and utilized coordinates of facial landmarks to calculate parameters.\n",
        "The parameters include areas between the eye and eyebrow, eyelids, lip\n",
        "landmarks, and distances between facial features."
      ],
      "metadata": {
        "id": "Pua9wXDehHBj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_area_eye_eyebrow_points(row):\n",
        "  x_coordinates_l = row[['eb_l_r_x','eb_l_c_x','eb_l_l_x','eye_l_r_most_x','eye_l_up_r_x','eye_l_up_l_x','eye_l_l_most_x']]\n",
        "  y_coordinates_l = row[['eb_l_r_y','eb_l_c_y','eb_l_l_y','eye_l_r_most_y','eye_l_up_r_y','eye_l_up_l_y','eye_l_l_most_y']]\n",
        "  x_coordinates_l = np.append(x_coordinates_l, x_coordinates_l[0])  # Close the polygon\n",
        "  y_coordinates_l = np.append(y_coordinates_l, y_coordinates_l[0])\n",
        "  area_l = 0.5 * np.abs(np.sum(x_coordinates_l[:-1] * y_coordinates_l[1:] - x_coordinates_l[1:] * y_coordinates_l[:-1]))\n",
        "  x_coordinates_r = row[['eb_r_r_x','eb_r_c_x','eb_r_l_x','eye_r_r_most_x','eye_r_up_r_x','eye_r_up_l_x','eye_r_l_most_x']]\n",
        "  y_coordinates_r = row[['eb_r_r_y','eb_r_c_y','eb_r_l_y','eye_r_r_most_y','eye_r_up_r_y','eye_r_up_l_y','eye_r_l_most_y']]\n",
        "  x_coordinates_r = np.append(x_coordinates_r, x_coordinates_r[0])  # Close the polygon\n",
        "  y_coordinates_r = np.append(y_coordinates_r, y_coordinates_r[0])\n",
        "  area_r = 0.5 * np.abs(np.sum(x_coordinates_r[:-1] * y_coordinates_r[1:] - x_coordinates_r[1:] * y_coordinates_r[:-1]))\n",
        "  return np.mean([area_l, area_r])\n",
        "\n",
        "df['area_eye_eyebrow_points'] = df.apply(calc_area_eye_eyebrow_points, axis=1)"
      ],
      "metadata": {
        "id": "OHX6SiMxhFgT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_area_eye_points(row):\n",
        "  x_coordinates_l = row[['eye_l_dow_r_x','eye_l_dow_l_x','eye_l_r_most_x','eye_l_up_r_x','eye_l_up_l_x','eye_l_l_most_x']]\n",
        "  y_coordinates_l = row[['eye_l_dow_r_y','eye_l_dow_l_y','eye_l_r_most_y','eye_l_up_r_y','eye_l_up_l_y','eye_l_l_most_y']]\n",
        "  x_coordinates_l = np.append(x_coordinates_l, x_coordinates_l[0])  # Close the polygon\n",
        "  y_coordinates_l = np.append(y_coordinates_l, y_coordinates_l[0])\n",
        "  area_l = 0.5 * np.abs(np.sum(x_coordinates_l[:-1] * y_coordinates_l[1:] - x_coordinates_l[1:] * y_coordinates_l[:-1]))\n",
        "  x_coordinates_r = row[['eye_r_dow_r_x','eye_r_dow_l_x','eye_r_r_most_x','eye_r_up_r_x','eye_r_up_l_x','eye_r_l_most_x']]\n",
        "  y_coordinates_r = row[['eye_r_dow_r_y','eye_r_dow_l_y','eye_r_r_most_y','eye_r_up_r_y','eye_r_up_l_y','eye_r_l_most_y']]\n",
        "  x_coordinates_r = np.append(x_coordinates_r, x_coordinates_r[0])  # Close the polygon\n",
        "  y_coordinates_r = np.append(y_coordinates_r, y_coordinates_r[0])\n",
        "  area_r = 0.5 * np.abs(np.sum(x_coordinates_r[:-1] * y_coordinates_r[1:] - x_coordinates_r[1:] * y_coordinates_r[:-1]))\n",
        "  return np.mean([area_l, area_r])\n",
        "\n",
        "df['area_eye_points'] = df.apply(calc_area_eye_points, axis=1)"
      ],
      "metadata": {
        "id": "xaMD2H1IhNXv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def infer_lip_landmarks(row):\n",
        "    upper_lip_points = np.array(row[['lip_up_1_x', 'lip_up_1_y', 'lip_up_2_x', 'lip_up_2_y', 'lip_up_3_x', 'lip_up_3_y']])\n",
        "    lower_lip_points = np.array(row[['lip_dow_1_x', 'lip_dow_1_y', 'lip_dow_2_x', 'lip_dow_2_y', 'lip_dow_3_x', 'lip_dow_3_y']])\n",
        "\n",
        "    upper_midpoint = np.mean(upper_lip_points.reshape(3, 2), axis=0)\n",
        "    lower_midpoint = np.mean(lower_lip_points.reshape(3, 2), axis=0)\n",
        "    vertical_distance = np.linalg.norm(upper_midpoint - lower_midpoint)\n",
        "    return vertical_distance\n",
        "\n",
        "df['lip_landmarks_distance'] = df.apply(infer_lip_landmarks, axis=1)"
      ],
      "metadata": {
        "id": "LVJ8OmHShPw2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#two types of nose wrinkle\n",
        "\n",
        "df['distance_eb_cen_nose_cen'] = np.sqrt(\n",
        "    (df['eb_cen_x'] - df['nose_cen_x'])**2 + (df['eb_cen_y'] - df['nose_cen_y'])**2\n",
        ")\n",
        "\n",
        "df['distance_eb_cen_nose_tip'] = np.sqrt(\n",
        "    (df['eb_cen_x'] - df['nose_tip_x'])**2 + (df['eb_cen_y'] - df['nose_tip_y'])**2\n",
        ")"
      ],
      "metadata": {
        "id": "vU9p3tNThSgG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "There 12271 images for training and 3068 images for testing."
      ],
      "metadata": {
        "id": "8XCZr5E1hdVU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_data = df[df['img_name'].str.startswith('test')]\n",
        "train_data = df[df['img_name'].str.startswith('train')]"
      ],
      "metadata": {
        "id": "PS6cJAMdhgMk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As this is an affective dataset and some of the images are turned away or unclear, we are only taking the images which has not much deviation from the 3 centre points of the face."
      ],
      "metadata": {
        "id": "zroXQyPziJTj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['vals'] = df[['eb_cen_x','nose_cen_x','lip_up_3_x','lip_dow_3_x']].values.max(1) - df[['eb_cen_x','nose_cen_x','lip_up_3_x','lip_dow_3_x']].values.min(1)\n",
        "df = df.loc[df['vals'] <= 1]"
      ],
      "metadata": {
        "id": "uFf4NelHiI9p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We are splitting the data into the 7 labels given.<br>\n",
        "Emotion labels:<br>\n",
        "1: Surprise<br>\n",
        "2: Fear<br>\n",
        "3: Disgust<br>\n",
        "4: Happiness<br>\n",
        "5: Sadness<br>\n",
        "6: Anger<br>\n",
        "7: Neutral<br>\n",
        "Confidence intervals are derived to quantify variability in each emotion\n",
        "across facial features.\n"
      ],
      "metadata": {
        "id": "nRsAgM56i6Cc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sur = train_data[train_data['emotion'] == 1]\n",
        "fear = train_data[train_data['emotion'] == 2]\n",
        "disg = train_data[train_data['emotion'] == 3]\n",
        "happ = train_data[train_data['emotion'] == 4]\n",
        "sad = train_data[train_data['emotion'] == 5]\n",
        "ang = train_data[train_data['emotion'] == 6]\n",
        "neu = train_data[train_data['emotion'] == 7]"
      ],
      "metadata": {
        "id": "OeEqYAD8i8_a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "params = ['area_eye_eyebrow_points','area_eye_points','lip_landmarks_distance','distance_eb_cen_nose_cen','distance_eb_cen_nose_tip']\n",
        "emos = ['sur','fear','disg','happ','sad','ang','neu']\n",
        "\n",
        "def calc_confi_int(params, emo_data):\n",
        "  res = []\n",
        "  for p in params:\n",
        "    data = emo_data[p]\n",
        "    m = np.mean(data)\n",
        "    se = np.std(data) / math.sqrt(len(data))\n",
        "    ci = [m - se * 3.891, m + se * 3.891]\n",
        "    res.append(ci)\n",
        "  return res\n"
      ],
      "metadata": {
        "id": "UYDpiW18jcSJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sur_ci = calc_confi_int(params,sur)\n",
        "fear_ci = calc_confi_int(params,fear)\n",
        "disg_ci = calc_confi_int(params,disg)\n",
        "happ_ci = calc_confi_int(params,happ)\n",
        "sad_ci = calc_confi_int(params,sad)\n",
        "ang_ci = calc_confi_int(params,ang)\n",
        "neu_ci = calc_confi_int(params,neu)\n",
        "\n",
        "emo_ci = []\n",
        "emo_ci.append(sur_ci)\n",
        "emo_ci.append(fear_ci)\n",
        "emo_ci.append(disg_ci)\n",
        "emo_ci.append(happ_ci)\n",
        "emo_ci.append(sad_ci)\n",
        "emo_ci.append(ang_ci)\n",
        "emo_ci.append(neu_ci)"
      ],
      "metadata": {
        "id": "2gsrC1Uejg58"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then we are calculating the upper and lower approximation spaces."
      ],
      "metadata": {
        "id": "Ptsr7k5LkFFQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epsilon = 1\n",
        "\n",
        "def calc_approx_spaces(data):\n",
        "    low = []\n",
        "    up = set()\n",
        "    d = []\n",
        "\n",
        "    for i in range(7):\n",
        "        emo = emo_ci[i]\n",
        "        emo_ct = 0\n",
        "\n",
        "        for j in range(5):\n",
        "            interv = [data[j + 1] + epsilon, data[j + 1] - epsilon]\n",
        "\n",
        "            if emo[j][0] <= interv[0] and interv[1] <= emo[j][1]:\n",
        "                emo_ct += 1\n",
        "\n",
        "        # Decide whether to add the emotion to \"low\" or \"up\" based on emo_ct\n",
        "        if emo_ct >= 3:\n",
        "            low.append(emos[i])\n",
        "        elif emo_ct > 0 and emo_ct < 3:\n",
        "            up.add(emos[i])\n",
        "\n",
        "        d.append([emos[i], emo_ct])\n",
        "\n",
        "    return (low, up, d)\n",
        "\n",
        "test_data_params[['lower_approx', 'upper_approx', 'emo_data']] = test_data_params.apply(calc_approx_spaces, axis=1, result_type='expand')\n"
      ],
      "metadata": {
        "id": "ufbL2-W1kFeK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Thus this approach gives us the set of possible emotion that particular image can have."
      ],
      "metadata": {
        "id": "mOrhL0X-knEg"
      }
    }
  ]
}